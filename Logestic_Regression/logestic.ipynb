{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nihar Muniraju"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Load Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = make_classification(n_samples=1000, n_features=10, n_classes=2, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.3779567 ,  1.04389498,  1.04349443, ..., -0.0671922 ,\n",
       "         0.17547148, -1.04964564],\n",
       "       [-0.32525851,  1.27626282, -0.68612327, ...,  1.00663329,\n",
       "        -0.83369182,  0.95774417],\n",
       "       [ 0.73901891, -0.60090284, -0.17729436, ..., -0.21898072,\n",
       "         0.87864296, -1.25774001],\n",
       "       ...,\n",
       "       [ 0.67556288, -0.53841971, -1.29950008, ...,  2.04333597,\n",
       "         0.94738793,  0.79035376],\n",
       "       [ 2.62971021, -2.45289885, -1.35978523, ...,  0.37889809,\n",
       "        -1.97189411, -0.2522504 ],\n",
       "       [-1.79149103, -0.12190773,  0.53515332, ..., -1.94135733,\n",
       "         0.58900166, -1.00748218]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting the data to data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.377957</td>\n",
       "      <td>1.043895</td>\n",
       "      <td>1.043494</td>\n",
       "      <td>-0.101838</td>\n",
       "      <td>-1.617442</td>\n",
       "      <td>0.402713</td>\n",
       "      <td>0.913601</td>\n",
       "      <td>-0.067192</td>\n",
       "      <td>0.175471</td>\n",
       "      <td>-1.049646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.325259</td>\n",
       "      <td>1.276263</td>\n",
       "      <td>-0.686123</td>\n",
       "      <td>-2.463205</td>\n",
       "      <td>-0.489426</td>\n",
       "      <td>-0.240715</td>\n",
       "      <td>-1.469496</td>\n",
       "      <td>1.006633</td>\n",
       "      <td>-0.833692</td>\n",
       "      <td>0.957744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.739019</td>\n",
       "      <td>-0.600903</td>\n",
       "      <td>-0.177294</td>\n",
       "      <td>1.335714</td>\n",
       "      <td>-0.817332</td>\n",
       "      <td>-0.790047</td>\n",
       "      <td>1.457365</td>\n",
       "      <td>-0.218981</td>\n",
       "      <td>0.878643</td>\n",
       "      <td>-1.257740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.474312</td>\n",
       "      <td>-1.103002</td>\n",
       "      <td>1.189936</td>\n",
       "      <td>-0.800186</td>\n",
       "      <td>0.912377</td>\n",
       "      <td>-0.406451</td>\n",
       "      <td>-1.130950</td>\n",
       "      <td>1.985111</td>\n",
       "      <td>1.379029</td>\n",
       "      <td>1.041768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.927365</td>\n",
       "      <td>1.114796</td>\n",
       "      <td>0.080284</td>\n",
       "      <td>1.261064</td>\n",
       "      <td>0.761179</td>\n",
       "      <td>0.921563</td>\n",
       "      <td>0.440832</td>\n",
       "      <td>0.184645</td>\n",
       "      <td>-1.567739</td>\n",
       "      <td>-0.142107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1.538272</td>\n",
       "      <td>0.171629</td>\n",
       "      <td>0.075371</td>\n",
       "      <td>-0.957658</td>\n",
       "      <td>-1.066219</td>\n",
       "      <td>1.158096</td>\n",
       "      <td>-0.036964</td>\n",
       "      <td>0.123689</td>\n",
       "      <td>0.927871</td>\n",
       "      <td>-0.225003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-0.060266</td>\n",
       "      <td>0.095018</td>\n",
       "      <td>-0.271685</td>\n",
       "      <td>1.830560</td>\n",
       "      <td>0.219445</td>\n",
       "      <td>-0.341269</td>\n",
       "      <td>1.180088</td>\n",
       "      <td>-0.216876</td>\n",
       "      <td>-1.752938</td>\n",
       "      <td>-0.810152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.675563</td>\n",
       "      <td>-0.538420</td>\n",
       "      <td>-1.299500</td>\n",
       "      <td>0.747835</td>\n",
       "      <td>1.733898</td>\n",
       "      <td>-0.268044</td>\n",
       "      <td>-0.520953</td>\n",
       "      <td>2.043336</td>\n",
       "      <td>0.947388</td>\n",
       "      <td>0.790354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2.629710</td>\n",
       "      <td>-2.452899</td>\n",
       "      <td>-1.359785</td>\n",
       "      <td>1.592065</td>\n",
       "      <td>0.854157</td>\n",
       "      <td>1.618828</td>\n",
       "      <td>0.621701</td>\n",
       "      <td>0.378898</td>\n",
       "      <td>-1.971894</td>\n",
       "      <td>-0.252250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-1.791491</td>\n",
       "      <td>-0.121908</td>\n",
       "      <td>0.535153</td>\n",
       "      <td>-0.588085</td>\n",
       "      <td>-1.929461</td>\n",
       "      <td>-0.659900</td>\n",
       "      <td>0.754921</td>\n",
       "      <td>-1.941357</td>\n",
       "      <td>0.589002</td>\n",
       "      <td>-1.007482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0   -0.377957  1.043895  1.043494 -0.101838 -1.617442  0.402713  0.913601   \n",
       "1   -0.325259  1.276263 -0.686123 -2.463205 -0.489426 -0.240715 -1.469496   \n",
       "2    0.739019 -0.600903 -0.177294  1.335714 -0.817332 -0.790047  1.457365   \n",
       "3    0.474312 -1.103002  1.189936 -0.800186  0.912377 -0.406451 -1.130950   \n",
       "4    0.927365  1.114796  0.080284  1.261064  0.761179  0.921563  0.440832   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "995  1.538272  0.171629  0.075371 -0.957658 -1.066219  1.158096 -0.036964   \n",
       "996 -0.060266  0.095018 -0.271685  1.830560  0.219445 -0.341269  1.180088   \n",
       "997  0.675563 -0.538420 -1.299500  0.747835  1.733898 -0.268044 -0.520953   \n",
       "998  2.629710 -2.452899 -1.359785  1.592065  0.854157  1.618828  0.621701   \n",
       "999 -1.791491 -0.121908  0.535153 -0.588085 -1.929461 -0.659900  0.754921   \n",
       "\n",
       "            7         8         9  \n",
       "0   -0.067192  0.175471 -1.049646  \n",
       "1    1.006633 -0.833692  0.957744  \n",
       "2   -0.218981  0.878643 -1.257740  \n",
       "3    1.985111  1.379029  1.041768  \n",
       "4    0.184645 -1.567739 -0.142107  \n",
       "..        ...       ...       ...  \n",
       "995  0.123689  0.927871 -0.225003  \n",
       "996 -0.216876 -1.752938 -0.810152  \n",
       "997  2.043336  0.947388  0.790354  \n",
       "998  0.378898 -1.971894 -0.252250  \n",
       "999 -1.941357  0.589002 -1.007482  \n",
       "\n",
       "[1000 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "       0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 1, 1, 1, 0, 0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test  = train_test_split(X,y, test_size=0.30,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# implement logestic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = log.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.33104089e-01, 6.68959106e-02],\n",
       "       [6.59976832e-01, 3.40023168e-01],\n",
       "       [8.65439561e-01, 1.34560439e-01],\n",
       "       [9.59081747e-02, 9.04091825e-01],\n",
       "       [2.43108150e-01, 7.56891850e-01],\n",
       "       [5.76396931e-01, 4.23603069e-01],\n",
       "       [8.25188888e-01, 1.74811112e-01],\n",
       "       [2.29999952e-04, 9.99770000e-01],\n",
       "       [1.25363187e-02, 9.87463681e-01],\n",
       "       [2.73346597e-03, 9.97266534e-01],\n",
       "       [7.06227890e-03, 9.92937721e-01],\n",
       "       [5.68134296e-01, 4.31865704e-01],\n",
       "       [8.38796778e-02, 9.16120322e-01],\n",
       "       [9.73835584e-01, 2.61644162e-02],\n",
       "       [1.27501162e-02, 9.87249884e-01],\n",
       "       [8.06120072e-01, 1.93879928e-01],\n",
       "       [9.95125747e-01, 4.87425270e-03],\n",
       "       [1.78699988e-02, 9.82130001e-01],\n",
       "       [9.78717701e-01, 2.12822989e-02],\n",
       "       [3.90303620e-02, 9.60969638e-01],\n",
       "       [3.39139480e-02, 9.66086052e-01],\n",
       "       [3.13743686e-02, 9.68625631e-01],\n",
       "       [5.00274883e-02, 9.49972512e-01],\n",
       "       [8.18573651e-01, 1.81426349e-01],\n",
       "       [8.59038470e-01, 1.40961530e-01],\n",
       "       [9.12460521e-01, 8.75394788e-02],\n",
       "       [8.53285450e-01, 1.46714550e-01],\n",
       "       [8.63538338e-01, 1.36461662e-01],\n",
       "       [7.14069794e-01, 2.85930206e-01],\n",
       "       [1.50110810e-01, 8.49889190e-01],\n",
       "       [4.25748098e-04, 9.99574252e-01],\n",
       "       [6.18630454e-01, 3.81369546e-01],\n",
       "       [2.02970365e-02, 9.79702963e-01],\n",
       "       [4.31674190e-01, 5.68325810e-01],\n",
       "       [1.32602897e-04, 9.99867397e-01],\n",
       "       [9.79277212e-01, 2.07227884e-02],\n",
       "       [7.91505067e-05, 9.99920849e-01],\n",
       "       [2.79028629e-01, 7.20971371e-01],\n",
       "       [7.50191140e-01, 2.49808860e-01],\n",
       "       [9.78914019e-01, 2.10859811e-02],\n",
       "       [9.29298742e-01, 7.07012581e-02],\n",
       "       [5.07627084e-01, 4.92372916e-01],\n",
       "       [7.86334536e-01, 2.13665464e-01],\n",
       "       [1.02170326e-02, 9.89782967e-01],\n",
       "       [6.71001381e-01, 3.28998619e-01],\n",
       "       [2.28316835e-02, 9.77168316e-01],\n",
       "       [9.56906175e-04, 9.99043094e-01],\n",
       "       [2.80866655e-04, 9.99719133e-01],\n",
       "       [2.35383593e-04, 9.99764616e-01],\n",
       "       [5.95639599e-01, 4.04360401e-01],\n",
       "       [2.24986821e-01, 7.75013179e-01],\n",
       "       [1.87963545e-06, 9.99998120e-01],\n",
       "       [3.76191758e-03, 9.96238082e-01],\n",
       "       [1.47229167e-03, 9.98527708e-01],\n",
       "       [2.71064330e-02, 9.72893567e-01],\n",
       "       [1.06485998e-02, 9.89351400e-01],\n",
       "       [4.95368676e-01, 5.04631324e-01],\n",
       "       [9.70585084e-01, 2.94149162e-02],\n",
       "       [4.88523232e-02, 9.51147677e-01],\n",
       "       [5.89167160e-01, 4.10832840e-01],\n",
       "       [3.61611389e-01, 6.38388611e-01],\n",
       "       [9.39498551e-01, 6.05014489e-02],\n",
       "       [9.84757455e-01, 1.52425455e-02],\n",
       "       [6.89700912e-01, 3.10299088e-01],\n",
       "       [1.37200997e-03, 9.98627990e-01],\n",
       "       [1.09949522e-05, 9.99989005e-01],\n",
       "       [7.17407766e-01, 2.82592234e-01],\n",
       "       [9.33068344e-01, 6.69316556e-02],\n",
       "       [1.27246555e-02, 9.87275344e-01],\n",
       "       [9.95912281e-01, 4.08771888e-03],\n",
       "       [9.45014768e-01, 5.49852320e-02],\n",
       "       [9.72505405e-01, 2.74945952e-02],\n",
       "       [1.57767118e-02, 9.84223288e-01],\n",
       "       [7.02089863e-01, 2.97910137e-01],\n",
       "       [3.78336641e-03, 9.96216634e-01],\n",
       "       [7.88166769e-01, 2.11833231e-01],\n",
       "       [9.76950585e-03, 9.90230494e-01],\n",
       "       [9.08319915e-01, 9.16800853e-02],\n",
       "       [9.97668337e-01, 2.33166339e-03],\n",
       "       [9.78676555e-01, 2.13234453e-02],\n",
       "       [9.97859196e-01, 2.14080396e-03],\n",
       "       [9.62738467e-01, 3.72615329e-02],\n",
       "       [6.87123257e-01, 3.12876743e-01],\n",
       "       [9.65470028e-01, 3.45299723e-02],\n",
       "       [4.09424875e-03, 9.95905751e-01],\n",
       "       [6.80206407e-01, 3.19793593e-01],\n",
       "       [2.00265911e-02, 9.79973409e-01],\n",
       "       [9.70587240e-01, 2.94127604e-02],\n",
       "       [7.63313709e-01, 2.36686291e-01],\n",
       "       [5.93516932e-05, 9.99940648e-01],\n",
       "       [2.71967499e-03, 9.97280325e-01],\n",
       "       [1.16719400e-02, 9.88328060e-01],\n",
       "       [9.76638433e-01, 2.33615675e-02],\n",
       "       [1.90773686e-04, 9.99809226e-01],\n",
       "       [2.75472277e-01, 7.24527723e-01],\n",
       "       [2.66885863e-01, 7.33114137e-01],\n",
       "       [6.31794396e-01, 3.68205604e-01],\n",
       "       [2.23108158e-01, 7.76891842e-01],\n",
       "       [1.49891897e-04, 9.99850108e-01],\n",
       "       [5.41255917e-03, 9.94587441e-01],\n",
       "       [1.99221339e-01, 8.00778661e-01],\n",
       "       [8.53091208e-01, 1.46908792e-01],\n",
       "       [9.63745661e-01, 3.62543392e-02],\n",
       "       [9.68858604e-01, 3.11413963e-02],\n",
       "       [9.62889671e-01, 3.71103286e-02],\n",
       "       [9.90852701e-01, 9.14729857e-03],\n",
       "       [1.83724160e-02, 9.81627584e-01],\n",
       "       [9.52934925e-01, 4.70650748e-02],\n",
       "       [9.79501310e-01, 2.04986896e-02],\n",
       "       [9.74838735e-01, 2.51612650e-02],\n",
       "       [8.64561278e-04, 9.99135439e-01],\n",
       "       [2.63635565e-04, 9.99736364e-01],\n",
       "       [7.15816922e-01, 2.84183078e-01],\n",
       "       [5.20102473e-01, 4.79897527e-01],\n",
       "       [8.22118465e-01, 1.77881535e-01],\n",
       "       [9.93687723e-01, 6.31227662e-03],\n",
       "       [7.01689887e-01, 2.98310113e-01],\n",
       "       [4.08054578e-03, 9.95919454e-01],\n",
       "       [8.82580348e-01, 1.17419652e-01],\n",
       "       [9.18167868e-01, 8.18321316e-02],\n",
       "       [2.04191995e-01, 7.95808005e-01],\n",
       "       [8.30915134e-01, 1.69084866e-01],\n",
       "       [9.50759759e-01, 4.92402408e-02],\n",
       "       [9.95188524e-01, 4.81147615e-03],\n",
       "       [9.98081563e-01, 1.91843692e-03],\n",
       "       [9.94720644e-01, 5.27935599e-03],\n",
       "       [7.86910251e-01, 2.13089749e-01],\n",
       "       [9.59328264e-01, 4.06717360e-02],\n",
       "       [9.60584999e-01, 3.94150010e-02],\n",
       "       [2.78162831e-02, 9.72183717e-01],\n",
       "       [4.83504710e-01, 5.16495290e-01],\n",
       "       [9.76313056e-01, 2.36869436e-02],\n",
       "       [5.29536484e-03, 9.94704635e-01],\n",
       "       [8.95190218e-01, 1.04809782e-01],\n",
       "       [9.78725579e-01, 2.12744207e-02],\n",
       "       [5.70424328e-04, 9.99429576e-01],\n",
       "       [6.06597095e-04, 9.99393403e-01],\n",
       "       [9.97063519e-01, 2.93648136e-03],\n",
       "       [9.96770635e-01, 3.22936499e-03],\n",
       "       [2.80932364e-04, 9.99719068e-01],\n",
       "       [4.36681854e-02, 9.56331815e-01],\n",
       "       [3.67577620e-02, 9.63242238e-01],\n",
       "       [7.64929290e-02, 9.23507071e-01],\n",
       "       [9.99111854e-01, 8.88145827e-04],\n",
       "       [9.21724541e-01, 7.82754591e-02],\n",
       "       [8.47470908e-01, 1.52529092e-01],\n",
       "       [3.52211622e-03, 9.96477884e-01],\n",
       "       [1.99963628e-02, 9.80003637e-01],\n",
       "       [8.87815624e-01, 1.12184376e-01],\n",
       "       [2.04900489e-04, 9.99795100e-01],\n",
       "       [9.69272062e-01, 3.07279383e-02],\n",
       "       [5.93415564e-01, 4.06584436e-01],\n",
       "       [4.12434381e-01, 5.87565619e-01],\n",
       "       [9.62232914e-01, 3.77670862e-02],\n",
       "       [9.06571259e-01, 9.34287406e-02],\n",
       "       [9.68115138e-01, 3.18848620e-02],\n",
       "       [5.57913049e-02, 9.44208695e-01],\n",
       "       [1.71187994e-04, 9.99828812e-01],\n",
       "       [9.59561695e-01, 4.04383046e-02],\n",
       "       [4.27143830e-02, 9.57285617e-01],\n",
       "       [7.42046755e-01, 2.57953245e-01],\n",
       "       [9.97281089e-01, 2.71891147e-03],\n",
       "       [7.56358109e-01, 2.43641891e-01],\n",
       "       [1.43801088e-02, 9.85619891e-01],\n",
       "       [5.35312556e-01, 4.64687444e-01],\n",
       "       [4.45378258e-03, 9.95546217e-01],\n",
       "       [1.60029587e-01, 8.39970413e-01],\n",
       "       [9.38429814e-01, 6.15701856e-02],\n",
       "       [9.30104103e-01, 6.98958975e-02],\n",
       "       [7.97155690e-02, 9.20284431e-01],\n",
       "       [9.80799507e-01, 1.92004933e-02],\n",
       "       [3.40113855e-03, 9.96598861e-01],\n",
       "       [3.85767933e-03, 9.96142321e-01],\n",
       "       [9.23872609e-01, 7.61273909e-02],\n",
       "       [2.48244000e-03, 9.97517560e-01],\n",
       "       [1.42590198e-01, 8.57409802e-01],\n",
       "       [7.71857139e-01, 2.28142861e-01],\n",
       "       [7.15361824e-01, 2.84638176e-01],\n",
       "       [7.95802216e-03, 9.92041978e-01],\n",
       "       [2.90672971e-03, 9.97093270e-01],\n",
       "       [9.62804022e-01, 3.71959777e-02],\n",
       "       [3.95173272e-06, 9.99996048e-01],\n",
       "       [7.46521232e-01, 2.53478768e-01],\n",
       "       [2.68377139e-01, 7.31622861e-01],\n",
       "       [9.08001425e-01, 9.19985751e-02],\n",
       "       [6.29221189e-01, 3.70778811e-01],\n",
       "       [1.73092334e-04, 9.99826908e-01],\n",
       "       [2.88878674e-01, 7.11121326e-01],\n",
       "       [8.70348991e-01, 1.29651009e-01],\n",
       "       [4.65501083e-02, 9.53449892e-01],\n",
       "       [2.69925625e-04, 9.99730074e-01],\n",
       "       [9.18821208e-03, 9.90811788e-01],\n",
       "       [1.84058415e-05, 9.99981594e-01],\n",
       "       [9.21585305e-01, 7.84146951e-02],\n",
       "       [1.66148452e-01, 8.33851548e-01],\n",
       "       [4.28792808e-02, 9.57120719e-01],\n",
       "       [3.24218883e-01, 6.75781117e-01],\n",
       "       [2.88812742e-03, 9.97111873e-01],\n",
       "       [2.34274548e-03, 9.97657255e-01],\n",
       "       [5.66510205e-01, 4.33489795e-01],\n",
       "       [8.64460483e-02, 9.13553952e-01],\n",
       "       [1.63989586e-01, 8.36010414e-01],\n",
       "       [9.73141580e-01, 2.68584199e-02],\n",
       "       [1.48492890e-03, 9.98515071e-01],\n",
       "       [9.76142249e-01, 2.38577513e-02],\n",
       "       [9.20183372e-01, 7.98166284e-02],\n",
       "       [1.27799670e-04, 9.99872200e-01],\n",
       "       [8.14616098e-01, 1.85383902e-01],\n",
       "       [6.57619511e-02, 9.34238049e-01],\n",
       "       [8.05506424e-01, 1.94493576e-01],\n",
       "       [3.16841231e-02, 9.68315877e-01],\n",
       "       [3.85311660e-02, 9.61468834e-01],\n",
       "       [9.69954697e-01, 3.00453026e-02],\n",
       "       [6.65986768e-03, 9.93340132e-01],\n",
       "       [6.58151073e-01, 3.41848927e-01],\n",
       "       [4.54368859e-01, 5.45631141e-01],\n",
       "       [9.73084127e-01, 2.69158732e-02],\n",
       "       [9.90303001e-01, 9.69699858e-03],\n",
       "       [8.65783205e-01, 1.34216795e-01],\n",
       "       [7.15540687e-01, 2.84459313e-01],\n",
       "       [6.21203632e-01, 3.78796368e-01],\n",
       "       [9.14608618e-01, 8.53913819e-02],\n",
       "       [7.63263535e-01, 2.36736465e-01],\n",
       "       [1.27328969e-03, 9.98726710e-01],\n",
       "       [9.56775002e-01, 4.32249985e-02],\n",
       "       [8.81796794e-01, 1.18203206e-01],\n",
       "       [9.54741311e-01, 4.52586890e-02],\n",
       "       [9.37675309e-01, 6.23246915e-02],\n",
       "       [9.04350122e-01, 9.56498784e-02],\n",
       "       [4.36825205e-02, 9.56317480e-01],\n",
       "       [9.37566377e-01, 6.24336232e-02],\n",
       "       [2.67935975e-01, 7.32064025e-01],\n",
       "       [9.88332119e-01, 1.16678810e-02],\n",
       "       [9.37357607e-01, 6.26423933e-02],\n",
       "       [1.98870091e-01, 8.01129909e-01],\n",
       "       [7.53193594e-01, 2.46806406e-01],\n",
       "       [5.64637682e-05, 9.99943536e-01],\n",
       "       [2.35669383e-03, 9.97643306e-01],\n",
       "       [9.63223386e-01, 3.67766138e-02],\n",
       "       [9.91344273e-01, 8.65572690e-03],\n",
       "       [2.79414842e-02, 9.72058516e-01],\n",
       "       [1.73663772e-02, 9.82633623e-01],\n",
       "       [1.97654982e-05, 9.99980235e-01],\n",
       "       [9.97873229e-01, 2.12677091e-03],\n",
       "       [5.38568985e-02, 9.46143101e-01],\n",
       "       [1.14208934e-02, 9.88579107e-01],\n",
       "       [9.96664447e-01, 3.33555343e-03],\n",
       "       [9.34325785e-01, 6.56742147e-02],\n",
       "       [8.33456753e-05, 9.99916654e-01],\n",
       "       [4.38586824e-02, 9.56141318e-01],\n",
       "       [8.78527383e-01, 1.21472617e-01],\n",
       "       [1.02262699e-01, 8.97737301e-01],\n",
       "       [1.39702455e-01, 8.60297545e-01],\n",
       "       [7.38438745e-01, 2.61561255e-01],\n",
       "       [9.96218361e-01, 3.78163937e-03],\n",
       "       [2.96903603e-01, 7.03096397e-01],\n",
       "       [8.92354714e-01, 1.07645286e-01],\n",
       "       [9.84488536e-01, 1.55114638e-02],\n",
       "       [1.16290641e-04, 9.99883709e-01],\n",
       "       [9.80018027e-01, 1.99819730e-02],\n",
       "       [8.03911966e-01, 1.96088034e-01],\n",
       "       [1.38054725e-03, 9.98619453e-01],\n",
       "       [7.84488886e-01, 2.15511114e-01],\n",
       "       [1.03611401e-03, 9.98963886e-01],\n",
       "       [7.02865763e-01, 2.97134237e-01],\n",
       "       [6.23112023e-03, 9.93768880e-01],\n",
       "       [8.62299841e-01, 1.37700159e-01],\n",
       "       [9.53531098e-01, 4.64689022e-02],\n",
       "       [2.24165759e-01, 7.75834241e-01],\n",
       "       [2.89736651e-01, 7.10263349e-01],\n",
       "       [7.70379972e-01, 2.29620028e-01],\n",
       "       [8.96941856e-01, 1.03058144e-01],\n",
       "       [1.01542270e-02, 9.89845773e-01],\n",
       "       [3.29284863e-01, 6.70715137e-01],\n",
       "       [9.79115114e-01, 2.08848863e-02],\n",
       "       [3.21286101e-04, 9.99678714e-01],\n",
       "       [9.85080267e-02, 9.01491973e-01],\n",
       "       [6.73824799e-02, 9.32617520e-01],\n",
       "       [9.95957151e-01, 4.04284935e-03],\n",
       "       [1.46535483e-02, 9.85346452e-01],\n",
       "       [2.73619909e-05, 9.99972638e-01],\n",
       "       [9.70016883e-01, 2.99831167e-02],\n",
       "       [8.50873664e-01, 1.49126336e-01],\n",
       "       [6.52726598e-01, 3.47273402e-01],\n",
       "       [3.71328572e-01, 6.28671428e-01],\n",
       "       [9.57376655e-01, 4.26233447e-02],\n",
       "       [8.32142898e-01, 1.67857102e-01],\n",
       "       [8.56322585e-01, 1.43677415e-01],\n",
       "       [5.75653149e-02, 9.42434685e-01],\n",
       "       [8.93439186e-01, 1.06560814e-01],\n",
       "       [8.56747667e-01, 1.43252333e-01],\n",
       "       [8.86252236e-03, 9.91137478e-01],\n",
       "       [7.59051924e-01, 2.40948076e-01],\n",
       "       [2.86240052e-01, 7.13759948e-01],\n",
       "       [9.96145674e-01, 3.85432624e-03],\n",
       "       [6.95980974e-03, 9.93040190e-01],\n",
       "       [9.79049347e-01, 2.09506530e-02],\n",
       "       [4.46258951e-03, 9.95537410e-01],\n",
       "       [8.80047667e-01, 1.19952333e-01],\n",
       "       [9.71816536e-01, 2.81834640e-02]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.predict_proba(X_test) # for probaBILITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0.9166666666666666\n",
      "confusion [[146  11]\n",
      " [ 14 129]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92       157\n",
      "           1       0.92      0.90      0.91       143\n",
      "\n",
      "    accuracy                           0.92       300\n",
      "   macro avg       0.92      0.92      0.92       300\n",
      "weighted avg       0.92      0.92      0.92       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score =accuracy_score (y_test,y_pred)\n",
    "print(\"score\", score)\n",
    "confusion = confusion_matrix(y_test,y_pred)\n",
    "print(\"confusion\", confusion)\n",
    "\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning And Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "penality =['l1','l2','elasticnet']\n",
    "c_values = [100,10,1.0,0.1,0.01]\n",
    "solver=['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to put all the above values in the key value pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'penalty': ['l1', 'l2', 'elasticnet'],\n",
       " 'C': [100, 10, 1.0, 0.1, 0.01],\n",
       " 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params=dict(penalty=penality,C=c_values,solver=solver)\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search  CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv=StratifiedKFold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(estimator=model,param_grid=params,scoring='accuracy',cv=cv,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [100, 10, 1.0, 0.1, 0.01],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;sag&#x27;,\n",
       "                                    &#x27;saga&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [100, 10, 1.0, 0.1, 0.01],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;sag&#x27;,\n",
       "                                    &#x27;saga&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'C': [100, 10, 1.0, 0.1, 0.01],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
       "                                    'saga']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nihar\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "200 fits failed out of a total of 375.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nihar\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\nihar\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nihar\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nihar\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\nihar\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nihar\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nihar\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\nihar\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nihar\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nihar\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\nihar\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nihar\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nihar\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\nihar\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nihar\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nihar\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\nihar\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nihar\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nihar\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\nihar\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nihar\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nihar\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\nihar\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nihar\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nihar\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nihar\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\nihar\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nihar\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nihar\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "                   ^^^^^^^\n",
      "  File \"c:\\Users\\nihar\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nihar\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nihar\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nihar\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "                         ~~^~~~~~~~~~\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\nihar\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.91285714        nan 0.91285714 0.91285714\n",
      " 0.91285714 0.91285714 0.91285714 0.91285714        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.91285714\n",
      "        nan 0.91285714 0.91285714 0.91285714 0.91285714 0.91285714\n",
      " 0.91285714        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.91142857        nan 0.91142857 0.91142857\n",
      " 0.91142857 0.91142857 0.91142857 0.91142857        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.92285714\n",
      "        nan 0.92142857 0.91285714 0.91285714 0.91857143 0.91285714\n",
      " 0.91285714        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.92142857        nan 0.92428571 0.91285714\n",
      " 0.91285714 0.92285714 0.91285714 0.91285714        nan        nan\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [100, 10, 1.0, 0.1, 0.01],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;sag&#x27;,\n",
       "                                    &#x27;saga&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [100, 10, 1.0, 0.1, 0.01],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;sag&#x27;,\n",
       "                                    &#x27;saga&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'C': [100, 10, 1.0, 0.1, 0.01],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
       "                                    'saga']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
